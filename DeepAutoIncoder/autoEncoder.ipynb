{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss =  4950.22     testing loss =  137859.42\n",
      "training loss =  4062.3584     testing loss =  115997.54\n",
      "training loss =  3496.7659     testing loss =  105638.46\n",
      "training loss =  3154.3613     testing loss =  102942.305\n",
      "training loss =  2916.083     testing loss =  101949.56\n",
      "training loss =  2725.7957     testing loss =  99553.086\n",
      "training loss =  2580.1387     testing loss =  98509.234\n",
      "training loss =  2459.8735     testing loss =  97649.15\n",
      "training loss =  2360.7285     testing loss =  96785.99\n",
      "training loss =  2269.5996     testing loss =  96427.14\n",
      "training loss =  2172.2915     testing loss =  94177.91\n",
      "training loss =  2084.2307     testing loss =  91924.43\n",
      "training loss =  2007.3848     testing loss =  90469.02\n",
      "training loss =  1937.3011     testing loss =  89188.43\n",
      "training loss =  1837.2687     testing loss =  84288.0\n",
      "training loss =  1753.4242     testing loss =  80355.016\n",
      "training loss =  1657.0894     testing loss =  75594.81\n",
      "training loss =  1569.4156     testing loss =  71186.23\n",
      "training loss =  1480.999     testing loss =  65703.99\n",
      "training loss =  1430.6919     testing loss =  64765.098\n",
      "training loss =  1388.5924     testing loss =  64354.438\n",
      "training loss =  1338.7783     testing loss =  64011.996\n",
      "training loss =  1295.7562     testing loss =  63499.4\n",
      "training loss =  1246.6348     testing loss =  61893.13\n",
      "training loss =  1209.3083     testing loss =  62003.633\n",
      "training loss =  1171.6172     testing loss =  61779.203\n",
      "training loss =  1134.8477     testing loss =  61019.87\n",
      "training loss =  1100.3522     testing loss =  59794.598\n",
      "training loss =  1076.6816     testing loss =  61043.42\n",
      "training loss =  1048.0026     testing loss =  60989.105\n",
      "training loss =  1022.3956     testing loss =  61140.906\n",
      "training loss =  984.65845     testing loss =  59426.184\n",
      "training loss =  953.5208     testing loss =  58575.598\n",
      "training loss =  924.9696     testing loss =  58156.215\n",
      "training loss =  899.1642     testing loss =  57756.484\n",
      "training loss =  876.2274     testing loss =  57202.02\n",
      "training loss =  859.97217     testing loss =  57718.61\n",
      "training loss =  841.34326     testing loss =  57819.598\n",
      "training loss =  825.7587     testing loss =  58157.86\n",
      "training loss =  810.99316     testing loss =  58474.562\n",
      "training loss =  790.4381     testing loss =  57964.62\n",
      "training loss =  780.442     testing loss =  58322.62\n",
      "training loss =  757.5665     testing loss =  57193.96\n",
      "training loss =  751.2831     testing loss =  58253.11\n",
      "training loss =  737.4477     testing loss =  58246.43\n",
      "training loss =  720.7564     testing loss =  57860.137\n",
      "training loss =  716.0377     testing loss =  58695.91\n",
      "training loss =  708.8437     testing loss =  59308.633\n",
      "training loss =  693.755     testing loss =  58832.582\n",
      "training loss =  676.7074     testing loss =  58057.047\n",
      "training loss =  673.91345     testing loss =  58928.883\n",
      "training loss =  666.86163     testing loss =  59085.86\n",
      "training loss =  653.0401     testing loss =  58285.69\n",
      "training loss =  639.55347     testing loss =  58121.016\n",
      "training loss =  627.4873     testing loss =  57675.895\n",
      "training loss =  625.38293     testing loss =  58338.07\n",
      "training loss =  616.49243     testing loss =  58518.055\n",
      "training loss =  615.4639     testing loss =  59560.73\n",
      "training loss =  606.8599     testing loss =  59326.54\n",
      "training loss =  606.7361     testing loss =  59566.586\n",
      "training loss =  599.25464     testing loss =  59402.766\n",
      "training loss =  590.73584     testing loss =  59007.965\n",
      "training loss =  582.9819     testing loss =  58845.082\n",
      "training loss =  573.44135     testing loss =  58236.984\n",
      "training loss =  571.80225     testing loss =  58611.387\n",
      "training loss =  565.68994     testing loss =  58405.76\n",
      "training loss =  560.2471     testing loss =  58163.02\n",
      "training loss =  552.1578     testing loss =  57932.168\n",
      "training loss =  556.88495     testing loss =  58711.336\n",
      "training loss =  564.0516     testing loss =  60160.44\n",
      "training loss =  562.9573     testing loss =  60493.45\n",
      "training loss =  563.02216     testing loss =  60944.227\n",
      "training loss =  567.2881     testing loss =  61107.67\n",
      "training loss =  568.1334     testing loss =  61391.0\n",
      "training loss =  573.2601     testing loss =  62211.28\n",
      "training loss =  575.53845     testing loss =  62748.082\n",
      "training loss =  572.5598     testing loss =  62464.742\n",
      "training loss =  578.11334     testing loss =  63429.63\n",
      "training loss =  576.74054     testing loss =  63602.33\n",
      "training loss =  575.8159     testing loss =  63863.58\n",
      "training loss =  576.97516     testing loss =  64098.75\n",
      "training loss =  579.85986     testing loss =  64691.08\n",
      "training loss =  574.75104     testing loss =  64532.73\n",
      "training loss =  571.9987     testing loss =  64541.18\n",
      "training loss =  572.3718     testing loss =  65042.195\n",
      "training loss =  565.8969     testing loss =  64571.977\n",
      "training loss =  562.2714     testing loss =  64586.918\n",
      "training loss =  563.8053     testing loss =  64892.49\n",
      "training loss =  555.9984     testing loss =  64255.0\n",
      "training loss =  368.55667     testing loss =  36550.953\n",
      "training loss =  306.56152     testing loss =  26937.8\n",
      "training loss =  289.91705     testing loss =  26826.832\n",
      "training loss =  281.26135     testing loss =  26792.752\n",
      "training loss =  276.23523     testing loss =  26760.86\n",
      "training loss =  272.6601     testing loss =  26773.463\n",
      "training loss =  269.48718     testing loss =  26768.023\n",
      "training loss =  266.77698     testing loss =  26758.227\n",
      "training loss =  264.35867     testing loss =  26750.156\n",
      "training loss =  262.11685     testing loss =  26741.352\n",
      "training loss =  259.97726     testing loss =  26728.914\n",
      "training loss =  257.89664     testing loss =  26707.842\n",
      "training loss =  255.89275     testing loss =  26676.096\n",
      "training loss =  254.06389     testing loss =  26644.328\n",
      "training loss =  252.4552     testing loss =  26627.387\n",
      "training loss =  250.96655     testing loss =  26621.18\n",
      "training loss =  249.53517     testing loss =  26615.904\n",
      "training loss =  248.17381     testing loss =  26610.467\n",
      "training loss =  246.88777     testing loss =  26605.568\n",
      "training loss =  245.6701     testing loss =  26601.205\n",
      "training loss =  244.51422     testing loss =  26597.262\n",
      "training loss =  243.46896     testing loss =  26593.768\n",
      "training loss =  242.4753     testing loss =  26590.604\n",
      "training loss =  241.43001     testing loss =  26587.633\n",
      "training loss =  240.45363     testing loss =  26584.943\n",
      "training loss =  239.52774     testing loss =  26582.484\n",
      "training loss =  238.64459     testing loss =  26580.227\n",
      "training loss =  237.79977     testing loss =  26578.14\n",
      "training loss =  236.99017     testing loss =  26576.21\n",
      "training loss =  236.21332     testing loss =  26574.412\n",
      "training loss =  235.46701     testing loss =  26572.738\n",
      "training loss =  234.74902     testing loss =  26571.176\n",
      "training loss =  234.05878     testing loss =  26569.744\n",
      "training loss =  233.39404     testing loss =  26568.33\n",
      "training loss =  232.75037     testing loss =  26567.031\n",
      "training loss =  232.13141     testing loss =  26565.803\n",
      "training loss =  231.53522     testing loss =  26564.578\n",
      "training loss =  230.95718     testing loss =  26563.54\n",
      "training loss =  230.39836     testing loss =  26562.486\n",
      "training loss =  229.85861     testing loss =  26561.484\n",
      "training loss =  229.30722     testing loss =  26561.87\n",
      "training loss =  228.84491     testing loss =  26559.225\n",
      "training loss =  228.3727     testing loss =  26558.658\n",
      "training loss =  227.91052     testing loss =  26557.615\n",
      "training loss =  227.41936     testing loss =  26556.965\n",
      "training loss =  226.97415     testing loss =  26556.234\n",
      "training loss =  226.54259     testing loss =  26555.424\n",
      "training loss =  226.12465     testing loss =  26554.629\n",
      "training loss =  225.71764     testing loss =  26553.941\n",
      "training loss =  225.32286     testing loss =  26553.215\n",
      "training loss =  224.94124     testing loss =  26552.52\n",
      "training loss =  224.57077     testing loss =  26551.826\n",
      "training loss =  224.21143     testing loss =  26551.17\n",
      "training loss =  223.86339     testing loss =  26550.535\n",
      "training loss =  223.52625     testing loss =  26549.912\n",
      "training loss =  223.19946     testing loss =  26549.312\n",
      "training loss =  222.88287     testing loss =  26548.734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss =  222.57617     testing loss =  26548.18\n",
      "training loss =  222.27896     testing loss =  26547.64\n",
      "training loss =  221.9908     testing loss =  26547.12\n",
      "training loss =  221.71138     testing loss =  26546.611\n",
      "training loss =  221.44032     testing loss =  26546.113\n",
      "training loss =  221.17719     testing loss =  26545.62\n",
      "training loss =  220.92162     testing loss =  26545.13\n",
      "training loss =  220.67357     testing loss =  26544.65\n",
      "training loss =  220.43202     testing loss =  26544.158\n",
      "training loss =  220.19682     testing loss =  26543.678\n",
      "training loss =  219.96779     testing loss =  26543.201\n",
      "training loss =  219.74487     testing loss =  26542.732\n",
      "training loss =  219.52765     testing loss =  26542.262\n",
      "training loss =  219.31592     testing loss =  26541.807\n",
      "training loss =  219.1093     testing loss =  26541.295\n",
      "training loss =  218.90947     testing loss =  26540.924\n",
      "training loss =  218.71191     testing loss =  26540.51\n",
      "training loss =  218.52588     testing loss =  26540.357\n",
      "training loss =  218.30385     testing loss =  26539.262\n",
      "training loss =  218.14996     testing loss =  26539.322\n",
      "training loss =  217.96863     testing loss =  26538.99\n",
      "training loss =  217.7931     testing loss =  26538.652\n",
      "training loss =  217.62582     testing loss =  26538.34\n",
      "training loss =  217.45914     testing loss =  26538.043\n",
      "training loss =  217.29684     testing loss =  26537.756\n",
      "training loss =  217.1388     testing loss =  26537.48\n",
      "training loss =  216.98431     testing loss =  26537.227\n",
      "training loss =  216.83322     testing loss =  26536.98\n",
      "training loss =  216.68538     testing loss =  26536.744\n",
      "training loss =  216.54066     testing loss =  26536.521\n",
      "training loss =  216.3989     testing loss =  26536.3\n",
      "training loss =  216.26024     testing loss =  26536.094\n",
      "training loss =  216.1241     testing loss =  26535.887\n",
      "training loss =  215.99077     testing loss =  26535.691\n",
      "training loss =  215.86009     testing loss =  26535.496\n",
      "training loss =  215.7318     testing loss =  26535.3\n",
      "training loss =  215.60617     testing loss =  26535.11\n",
      "training loss =  215.48257     testing loss =  26534.918\n",
      "training loss =  215.36137     testing loss =  26534.725\n",
      "training loss =  215.24248     testing loss =  26534.537\n",
      "training loss =  215.12552     testing loss =  26534.34\n",
      "training loss =  215.01088     testing loss =  26534.146\n",
      "training loss =  214.89816     testing loss =  26533.95\n",
      "training loss =  214.78754     testing loss =  26533.75\n",
      "training loss =  214.67892     testing loss =  26533.553\n",
      "training loss =  214.57225     testing loss =  26533.35\n",
      "training loss =  214.46748     testing loss =  26533.146\n",
      "training loss =  214.36472     testing loss =  26532.943\n",
      "training loss =  214.26396     testing loss =  26532.74\n",
      "training loss =  214.17163     testing loss =  26532.54\n",
      "training loss =  214.06393     testing loss =  26532.26\n",
      "training loss =  213.97026     testing loss =  26532.078\n",
      "training loss =  213.87926     testing loss =  26531.912\n",
      "training loss =  213.78908     testing loss =  26531.754\n",
      "training loss =  213.69978     testing loss =  26531.564\n",
      "training loss =  213.61153     testing loss =  26531.373\n",
      "training loss =  213.52483     testing loss =  26531.182\n",
      "training loss =  213.43982     testing loss =  26530.992\n",
      "training loss =  213.35843     testing loss =  26530.828\n",
      "training loss =  213.27704     testing loss =  26530.633\n",
      "training loss =  213.19734     testing loss =  26530.473\n",
      "training loss =  213.11942     testing loss =  26530.3\n",
      "training loss =  213.04382     testing loss =  26530.145\n",
      "training loss =  212.96959     testing loss =  26529.982\n",
      "training loss =  212.89941     testing loss =  26529.834\n",
      "training loss =  212.82664     testing loss =  26529.682\n",
      "training loss =  212.75694     testing loss =  26529.537\n",
      "training loss =  212.68893     testing loss =  26529.389\n",
      "training loss =  212.62256     testing loss =  26529.27\n",
      "training loss =  212.55826     testing loss =  26529.135\n",
      "training loss =  212.49448     testing loss =  26529.01\n",
      "training loss =  212.43224     testing loss =  26528.885\n",
      "training loss =  212.37169     testing loss =  26528.768\n",
      "training loss =  212.3123     testing loss =  26528.654\n",
      "training loss =  212.25494     testing loss =  26528.54\n",
      "training loss =  212.19775     testing loss =  26528.438\n",
      "training loss =  212.14342     testing loss =  26528.316\n",
      "training loss =  212.0902     testing loss =  26528.246\n",
      "training loss =  212.03746     testing loss =  26528.145\n",
      "training loss =  211.98506     testing loss =  26528.045\n",
      "training loss =  211.93431     testing loss =  26527.96\n",
      "training loss =  211.88588     testing loss =  26527.873\n",
      "training loss =  211.8377     testing loss =  26527.785\n",
      "training loss =  211.79575     testing loss =  26527.701\n",
      "training loss =  211.74664     testing loss =  26527.64\n",
      "training loss =  211.70114     testing loss =  26527.564\n",
      "training loss =  211.65704     testing loss =  26527.496\n",
      "training loss =  211.61337     testing loss =  26527.418\n",
      "training loss =  211.57259     testing loss =  26527.361\n",
      "training loss =  211.53238     testing loss =  26527.297\n",
      "training loss =  211.49292     testing loss =  26527.225\n",
      "training loss =  211.45386     testing loss =  26527.176\n",
      "training loss =  211.41579     testing loss =  26527.117\n",
      "training loss =  211.38255     testing loss =  26527.076\n",
      "training loss =  211.34569     testing loss =  26527.016\n",
      "training loss =  211.30913     testing loss =  26526.959\n",
      "training loss =  211.27397     testing loss =  26526.922\n",
      "training loss =  211.24025     testing loss =  26526.867\n",
      "training loss =  211.20743     testing loss =  26526.834\n",
      "training loss =  211.1755     testing loss =  26526.795\n",
      "training loss =  211.1444     testing loss =  26526.748\n",
      "training loss =  211.11618     testing loss =  26526.7\n",
      "training loss =  211.08417     testing loss =  26526.684\n",
      "training loss =  211.05467     testing loss =  26526.646\n",
      "training loss =  211.02838     testing loss =  26526.615\n",
      "training loss =  210.99835     testing loss =  26526.58\n",
      "training loss =  210.97128     testing loss =  26526.549\n",
      "training loss =  210.94577     testing loss =  26526.531\n",
      "training loss =  210.91867     testing loss =  26526.498\n",
      "training loss =  210.89539     testing loss =  26526.475\n",
      "training loss =  210.86908     testing loss =  26526.463\n",
      "training loss =  210.8447     testing loss =  26526.436\n",
      "training loss =  210.82101     testing loss =  26526.424\n",
      "training loss =  210.7998     testing loss =  26526.395\n",
      "training loss =  210.77495     testing loss =  26526.383\n",
      "training loss =  210.75636     testing loss =  26526.363\n",
      "training loss =  210.7321     testing loss =  26526.354\n",
      "training loss =  210.70998     testing loss =  26526.35\n",
      "training loss =  210.69028     testing loss =  26526.332\n",
      "training loss =  210.66946     testing loss =  26526.328\n",
      "training loss =  210.64934     testing loss =  26526.322\n",
      "training loss =  210.63033     testing loss =  26526.316\n",
      "training loss =  210.61206     testing loss =  26526.312\n",
      "training loss =  210.59412     testing loss =  26526.307\n",
      "training loss =  210.57529     testing loss =  26526.31\n",
      "training loss =  210.55762     testing loss =  26526.309\n",
      "training loss =  210.54054     testing loss =  26526.309\n",
      "training loss =  210.52458     testing loss =  26526.309\n",
      "training loss =  210.50809     testing loss =  26526.31\n",
      "training loss =  210.49294     testing loss =  26526.305\n",
      "training loss =  210.47624     testing loss =  26526.33\n",
      "training loss =  210.46347     testing loss =  26526.32\n",
      "training loss =  210.44803     testing loss =  26526.338\n",
      "training loss =  210.43271     testing loss =  26526.352\n",
      "training loss =  210.41866     testing loss =  26526.357\n",
      "training loss =  210.40648     testing loss =  26526.371\n",
      "training loss =  210.39276     testing loss =  26526.377\n",
      "training loss =  210.37933     testing loss =  26526.389\n",
      "training loss =  210.3671     testing loss =  26526.406\n",
      "training loss =  210.35649     testing loss =  26526.416\n",
      "training loss =  210.34404     testing loss =  26526.432\n",
      "training loss =  210.33272     testing loss =  26526.447\n",
      "training loss =  210.32327     testing loss =  26526.455\n",
      "training loss =  210.3123     testing loss =  26526.473\n",
      "training loss =  210.30196     testing loss =  26526.492\n",
      "training loss =  210.29314     testing loss =  26526.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss =  210.28458     testing loss =  26526.518\n",
      "training loss =  210.27533     testing loss =  26526.537\n",
      "training loss =  210.26985     testing loss =  26526.543\n",
      "training loss =  210.26083     testing loss =  26526.568\n",
      "training loss =  210.25313     testing loss =  26526.578\n",
      "training loss =  210.24594     testing loss =  26526.592\n",
      "training loss =  210.2393     testing loss =  26526.604\n",
      "training loss =  210.2337     testing loss =  26526.611\n",
      "training loss =  210.22784     testing loss =  26526.621\n",
      "training loss =  210.2255     testing loss =  26526.604\n",
      "training loss =  210.2186     testing loss =  26526.643\n",
      "training loss =  210.21347     testing loss =  26526.64\n",
      "training loss =  210.2091     testing loss =  26526.639\n",
      "training loss =  210.20515     testing loss =  26526.639\n",
      "training loss =  210.20155     testing loss =  26526.639\n",
      "training loss =  210.19814     testing loss =  26526.639\n",
      "training loss =  210.19496     testing loss =  26526.645\n",
      "training loss =  210.19286     testing loss =  26526.64\n",
      "training loss =  210.19017     testing loss =  26526.63\n",
      "training loss =  210.1865     testing loss =  26526.637\n",
      "training loss =  210.18372     testing loss =  26526.633\n",
      "training loss =  210.181     testing loss =  26526.63\n",
      "training loss =  210.17921     testing loss =  26526.627\n",
      "training loss =  210.17783     testing loss =  26526.629\n",
      "training loss =  210.17522     testing loss =  26526.629\n",
      "training loss =  210.17429     testing loss =  26526.62\n",
      "training loss =  210.17177     testing loss =  26526.625\n",
      "training loss =  210.16986     testing loss =  26526.623\n",
      "training loss =  210.16876     testing loss =  26526.621\n",
      "training loss =  210.16696     testing loss =  26526.615\n",
      "training loss =  210.16547     testing loss =  26526.617\n",
      "training loss =  210.16472     testing loss =  26526.61\n",
      "training loss =  210.16278     testing loss =  26526.611\n",
      "training loss =  210.16158     testing loss =  26526.61\n",
      "training loss =  210.16052     testing loss =  26526.613\n",
      "training loss =  210.16039     testing loss =  26526.61\n",
      "training loss =  210.15947     testing loss =  26526.604\n",
      "training loss =  210.15822     testing loss =  26526.605\n",
      "training loss =  210.1565     testing loss =  26526.602\n",
      "training loss =  210.15549     testing loss =  26526.604\n",
      "training loss =  210.15466     testing loss =  26526.6\n",
      "training loss =  210.15434     testing loss =  26526.6\n",
      "training loss =  210.15324     testing loss =  26526.598\n",
      "training loss =  210.1549     testing loss =  26526.6\n",
      "training loss =  210.15268     testing loss =  26526.596\n",
      "training loss =  210.15149     testing loss =  26526.596\n",
      "training loss =  210.15068     testing loss =  26526.596\n",
      "training loss =  210.15016     testing loss =  26526.596\n",
      "training loss =  210.15042     testing loss =  26526.596\n",
      "training loss =  210.14926     testing loss =  26526.594\n",
      "training loss =  210.149     testing loss =  26526.594\n",
      "training loss =  210.14853     testing loss =  26526.592\n",
      "training loss =  210.14803     testing loss =  26526.594\n",
      "training loss =  210.14743     testing loss =  26526.592\n",
      "training loss =  210.14743     testing loss =  26526.594\n",
      "training loss =  210.14682     testing loss =  26526.592\n",
      "training loss =  210.14642     testing loss =  26526.588\n",
      "training loss =  210.1459     testing loss =  26526.588\n",
      "training loss =  210.14563     testing loss =  26526.588\n",
      "training loss =  210.14694     testing loss =  26526.588\n",
      "training loss =  210.14572     testing loss =  26526.582\n",
      "training loss =  210.14507     testing loss =  26526.582\n",
      "training loss =  210.14471     testing loss =  26526.582\n",
      "training loss =  210.14429     testing loss =  26526.586\n",
      "training loss =  210.1442     testing loss =  26526.588\n",
      "training loss =  210.14403     testing loss =  26526.584\n",
      "training loss =  210.14423     testing loss =  26526.582\n",
      "training loss =  210.14357     testing loss =  26526.582\n",
      "training loss =  210.1434     testing loss =  26526.582\n",
      "training loss =  210.14317     testing loss =  26526.582\n",
      "training loss =  210.14288     testing loss =  26526.58\n",
      "training loss =  210.1429     testing loss =  26526.58\n",
      "training loss =  210.1426     testing loss =  26526.58\n",
      "training loss =  210.1426     testing loss =  26526.58\n",
      "training loss =  210.14227     testing loss =  26526.58\n",
      "training loss =  210.1424     testing loss =  26526.578\n",
      "training loss =  210.14233     testing loss =  26526.578\n",
      "training loss =  210.14198     testing loss =  26526.578\n",
      "training loss =  210.14189     testing loss =  26526.576\n",
      "training loss =  210.14182     testing loss =  26526.578\n",
      "training loss =  210.14156     testing loss =  26526.578\n",
      "training loss =  210.1417     testing loss =  26526.578\n",
      "training loss =  210.14325     testing loss =  26526.576\n",
      "training loss =  210.14166     testing loss =  26526.578\n",
      "training loss =  210.14156     testing loss =  26526.576\n",
      "training loss =  210.14412     testing loss =  26526.578\n",
      "training loss =  210.1419     testing loss =  26526.576\n",
      "training loss =  210.14136     testing loss =  26526.578\n",
      "training loss =  210.14105     testing loss =  26526.576\n",
      "training loss =  210.14172     testing loss =  26526.566\n",
      "training loss =  210.14137     testing loss =  26526.574\n",
      "training loss =  210.14066     testing loss =  26526.578\n",
      "training loss =  210.14049     testing loss =  26526.576\n",
      "training loss =  210.1407     testing loss =  26526.574\n",
      "training loss =  210.14066     testing loss =  26526.578\n",
      "training loss =  210.14053     testing loss =  26526.576\n",
      "training loss =  210.14102     testing loss =  26526.574\n",
      "training loss =  210.14041     testing loss =  26526.578\n",
      "training loss =  210.14008     testing loss =  26526.576\n",
      "training loss =  210.13972     testing loss =  26526.576\n",
      "training loss =  210.14468     testing loss =  26526.566\n",
      "training loss =  210.14305     testing loss =  26526.568\n",
      "training loss =  210.14117     testing loss =  26526.574\n",
      "training loss =  210.14027     testing loss =  26526.576\n",
      "training loss =  210.13979     testing loss =  26526.574\n",
      "training loss =  210.1421     testing loss =  26526.57\n",
      "training loss =  210.14114     testing loss =  26526.584\n",
      "training loss =  210.14056     testing loss =  26526.576\n",
      "training loss =  210.14015     testing loss =  26526.578\n",
      "training loss =  210.13974     testing loss =  26526.572\n",
      "training loss =  210.1458     testing loss =  26526.514\n",
      "training loss =  210.1414     testing loss =  26526.588\n",
      "training loss =  210.14066     testing loss =  26526.578\n",
      "training loss =  210.13983     testing loss =  26526.574\n",
      "training loss =  210.13928     testing loss =  26526.572\n",
      "training loss =  210.13911     testing loss =  26526.576\n",
      "training loss =  210.14519     testing loss =  26526.578\n",
      "training loss =  210.14261     testing loss =  26526.574\n",
      "training loss =  210.14081     testing loss =  26526.574\n",
      "training loss =  210.14009     testing loss =  26526.574\n",
      "training loss =  210.13947     testing loss =  26526.574\n",
      "training loss =  210.13896     testing loss =  26526.574\n",
      "training loss =  210.13863     testing loss =  26526.572\n",
      "training loss =  210.13847     testing loss =  26526.572\n",
      "training loss =  210.13925     testing loss =  26526.568\n",
      "training loss =  210.13892     testing loss =  26526.572\n",
      "training loss =  210.13843     testing loss =  26526.572\n",
      "training loss =  210.13832     testing loss =  26526.574\n",
      "training loss =  210.13899     testing loss =  26526.586\n",
      "training loss =  210.13959     testing loss =  26526.584\n",
      "training loss =  210.13881     testing loss =  26526.574\n",
      "training loss =  210.13835     testing loss =  26526.572\n",
      "training loss =  210.1402     testing loss =  26526.549\n",
      "training loss =  210.13985     testing loss =  26526.576\n",
      "training loss =  210.1389     testing loss =  26526.574\n",
      "training loss =  210.13835     testing loss =  26526.574\n",
      "training loss =  210.13803     testing loss =  26526.572\n",
      "training loss =  210.13788     testing loss =  26526.572\n",
      "training loss =  210.13864     testing loss =  26526.572\n",
      "training loss =  210.13814     testing loss =  26526.572\n",
      "training loss =  210.1378     testing loss =  26526.572\n",
      "training loss =  210.14291     testing loss =  26526.557\n",
      "training loss =  210.14056     testing loss =  26526.564\n",
      "training loss =  210.13866     testing loss =  26526.572\n",
      "training loss =  210.13799     testing loss =  26526.572\n",
      "training loss =  210.13766     testing loss =  26526.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss =  210.13765     testing loss =  26526.57\n",
      "training loss =  210.13754     testing loss =  26526.57\n",
      "training loss =  210.13747     testing loss =  26526.57\n",
      "training loss =  210.13783     testing loss =  26526.57\n",
      "training loss =  210.1377     testing loss =  26526.57\n",
      "training loss =  210.13742     testing loss =  26526.57\n",
      "training loss =  210.13815     testing loss =  26526.57\n",
      "training loss =  210.13754     testing loss =  26526.57\n",
      "training loss =  210.13747     testing loss =  26526.57\n",
      "training loss =  210.13727     testing loss =  26526.57\n",
      "training loss =  210.1387     testing loss =  26526.57\n",
      "training loss =  210.13782     testing loss =  26526.57\n",
      "training loss =  210.13744     testing loss =  26526.57\n",
      "training loss =  210.13725     testing loss =  26526.57\n",
      "training loss =  210.13763     testing loss =  26526.57\n",
      "training loss =  210.13736     testing loss =  26526.57\n",
      "training loss =  210.1372     testing loss =  26526.57\n",
      "training loss =  210.13745     testing loss =  26526.57\n",
      "training loss =  210.13737     testing loss =  26526.57\n",
      "training loss =  210.13718     testing loss =  26526.57\n",
      "training loss =  210.13756     testing loss =  26526.574\n",
      "training loss =  210.13766     testing loss =  26526.57\n",
      "training loss =  210.13716     testing loss =  26526.57\n",
      "training loss =  210.13779     testing loss =  26526.578\n",
      "training loss =  210.13899     testing loss =  26526.572\n",
      "training loss =  210.13766     testing loss =  26526.57\n",
      "training loss =  210.13728     testing loss =  26526.57\n",
      "training loss =  210.1371     testing loss =  26526.57\n",
      "training loss =  210.137     testing loss =  26526.57\n",
      "training loss =  210.13693     testing loss =  26526.57\n",
      "training loss =  210.13693     testing loss =  26526.57\n",
      "training loss =  210.13696     testing loss =  26526.57\n",
      "training loss =  210.13693     testing loss =  26526.57\n",
      "training loss =  210.13693     testing loss =  26526.57\n",
      "training loss =  210.13693     testing loss =  26526.57\n",
      "training loss =  210.13689     testing loss =  26526.57\n",
      "training loss =  210.13724     testing loss =  26526.566\n",
      "training loss =  210.13704     testing loss =  26526.57\n",
      "training loss =  210.13692     testing loss =  26526.57\n",
      "training loss =  210.13684     testing loss =  26526.57\n",
      "training loss =  210.13693     testing loss =  26526.57\n",
      "training loss =  210.13683     testing loss =  26526.57\n",
      "training loss =  210.13681     testing loss =  26526.57\n",
      "training loss =  210.13687     testing loss =  26526.57\n",
      "training loss =  210.13683     testing loss =  26526.57\n",
      "training loss =  210.1368     testing loss =  26526.57\n",
      "training loss =  210.1368     testing loss =  26526.57\n",
      "training loss =  210.1368     testing loss =  26526.57\n",
      "training loss =  210.13692     testing loss =  26526.57\n",
      "training loss =  210.13681     testing loss =  26526.57\n",
      "training loss =  210.13678     testing loss =  26526.57\n",
      "training loss =  210.1368     testing loss =  26526.57\n",
      "training loss =  210.13782     testing loss =  26526.572\n",
      "training loss =  210.13766     testing loss =  26526.57\n",
      "training loss =  210.13698     testing loss =  26526.57\n",
      "training loss =  210.13687     testing loss =  26526.57\n",
      "training loss =  210.13681     testing loss =  26526.57\n",
      "training loss =  210.13678     testing loss =  26526.57\n",
      "training loss =  210.13675     testing loss =  26526.57\n",
      "training loss =  210.13673     testing loss =  26526.57\n",
      "training loss =  210.13675     testing loss =  26526.57\n",
      "training loss =  210.13673     testing loss =  26526.57\n",
      "training loss =  210.13675     testing loss =  26526.57\n",
      "training loss =  210.13673     testing loss =  26526.57\n",
      "training loss =  210.13673     testing loss =  26526.57\n",
      "training loss =  210.13673     testing loss =  26526.57\n",
      "training loss =  210.13673     testing loss =  26526.57\n",
      "training loss =  210.13675     testing loss =  26526.57\n",
      "training loss =  210.13673     testing loss =  26526.57\n",
      "training loss =  210.13673     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13673     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13712     testing loss =  26526.57\n",
      "training loss =  210.13673     testing loss =  26526.57\n",
      "training loss =  210.13673     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.568\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss =  210.1367     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13673     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.57\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n",
      "training loss =  210.13672     testing loss =  26526.574\n"
     ]
    }
   ],
   "source": [
    "from module.DeepAutoEncoder import DeepAutoEncoder\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "mnist = tf.keras.datasets.mnist #load minst data\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data() #load minst data\n",
    "x_train = x_train/255 #normalize\n",
    "np.random.shuffle(x_train) #shuffle\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]) #flatten\n",
    "x_test = x_test/255 #normalize\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]) #flatten\n",
    "np.random.shuffle(x_test) #shuffle\n",
    "\n",
    "model = DeepAutoEncoder(x_train[:1000],x_test[:1000]) #build model\n",
    "\n",
    "trainLoss,testLoss = model.train(0.01,0.1,[64,16,4],1000,32) #train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1adc3e6d128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(\n",
    "    np.array(range(0, len(testLoss)))/float(len(testLoss)-1)*(len(trainLoss)-1), \n",
    "    np.log(testLoss), \n",
    "    label=\"Test loss\"\n",
    ")\n",
    "plt.plot(\n",
    "    np.log(trainLoss), \n",
    "    label=\"Train loss\"\n",
    ")\n",
    "plt.title(\"Training errors over time (on a logarithmic scale)\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log(Loss)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我覺得 loss 一直沒下去有幾種可能一種是說，我的訓練資料是圖片，所以可能要加conv 跟 deconv會有比較好的效果，不過也有可能是單純參數沒有調整好就是了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
